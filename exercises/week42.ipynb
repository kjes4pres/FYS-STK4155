{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises week 42\n",
    "\n",
    "**Kjersti Stangeland**\n",
    "**October 13-17, 2025**\n",
    "\n",
    "Date: **Deadline is Friday October 17 at midnight**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overarching aims of the exercises this week\n",
    "\n",
    "The aim of the exercises this week is to train the neural network you implemented last week.\n",
    "\n",
    "To train neural networks, we use gradient descent, since there is no analytical expression for the optimal parameters. This means you will need to compute the gradient of the cost function wrt. the network parameters. And then you will need to implement some gradient method.\n",
    "\n",
    "You will begin by computing gradients for a network with one layer, then two layers, then any number of layers. Keeping track of the shapes and doing things step by step will be very important this week.\n",
    "\n",
    "We recommend that you do the exercises this week by editing and running this notebook file, as it includes some checks along the way that you have implemented the neural network correctly, and running small parts of the code at a time will be important for understanding the methods. If you have trouble running a notebook, you can run this notebook in google colab instead(https://colab.research.google.com/drive/1FfvbN0XlhV-lATRPyGRTtTBnJr3zNuHL#offline=true&sandboxMode=true), though we recommend that you set up VSCode and your python environment to run code like this locally.\n",
    "\n",
    "First, some setup code that you will need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np  # We need to use this numpy wrapper to make automatic differentiation work later\n",
    "from autograd import grad, elementwise_grad\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Defining some activation functions\n",
    "def ReLU(z):\n",
    "    return np.where(z > 0, z, 0)\n",
    "\n",
    "\n",
    "# Derivative of the ReLU function\n",
    "def ReLU_der(z):\n",
    "    return np.where(z > 0, 1, 0)\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def mse(predict, target):\n",
    "    return np.mean((predict - target) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 - Understand the feed forward pass\n",
    "\n",
    "**a)** Complete last weeks' exercises if you haven't already (recommended).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 - Gradient with one layer using autograd\n",
    "\n",
    "For the first few exercises, we will not use batched inputs. Only a single input vector is passed through the layer at a time.\n",
    "\n",
    "In this exercise you will compute the gradient of a single layer. You only need to change the code in the cells right below an exercise, the rest works out of the box. Feel free to make changes and see how stuff works though!\n",
    "\n",
    "**a)** If the weights and bias of a layer has shapes (10, 4) and (10), what will the shapes of the gradients of the cost function wrt. these weights and this bias be?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer 2a):__\n",
    "\n",
    "From the lecture notes:\n",
    "\n",
    "$\\frac{\\partial C}{\\partial w_{jk}^l} = \\delta_j^l \\cdot a_k^{l-1}$, with: $\\delta_j^l = \\frac{\\partial C}{\\partial a_j^l} \\cdot \\sigma '$,  which is the gradient for the weigth $w_{jk}^l$, which corresponds to layer $l$ and node $jk$. For the bias, the gradient is $\\frac{\\partial C}{\\partial b_j^l} = \\delta_j^l$, where: $\\delta_j^l = \\frac{\\partial C}{\\partial a_j^l} \\cdot \\sigma '$. \n",
    "\n",
    "With weights with shape (10,4) and bias (10,), then the input is (4,). So $z = W*x + b$ has shape (10,), and then the activation function $a = \\sigma(z)$ has also shape (10,). So the gradient of the bias must also have shape (10,). The gradient of the weight has shape (10, 4). \n",
    "\n",
    "Say that j is the number of nodes, k is the number of inputs, then this reasoning makes sense at least in my brain. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** Complete the feed_forward_one_layer function. It should use the sigmoid activation function. Also define the weigth and bias with the correct shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_one_layer(W, b, x):\n",
    "    z = W @ x + b\n",
    "    a = sigmoid(z)\n",
    "    return a\n",
    "\n",
    "\n",
    "def cost_one_layer(W, b, x, target):\n",
    "    predict = feed_forward_one_layer(W, b, x)\n",
    "    return mse(predict, target)\n",
    "\n",
    "\n",
    "x = np.random.rand(2)\n",
    "target = np.random.rand(3)\n",
    "\n",
    "W = np.random.randn(3, 2)\n",
    "b = np.random.randn(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Compute the gradient of the cost function wrt. the weigth and bias by running the cell below. You will not need to change anything, just make sure it runs by defining things correctly in the cell above. This code uses the autograd package which uses backprogagation to compute the gradient!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02138296  0.01262527]\n",
      " [-0.02122727 -0.01253334]\n",
      " [ 0.00959348  0.00566434]] [ 0.06176618 -0.06131646  0.02771145]\n"
     ]
    }
   ],
   "source": [
    "autograd_one_layer = grad(cost_one_layer, [0, 1])\n",
    "W_g, b_g = autograd_one_layer(W, b, x, target)\n",
    "print(W_g, b_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 - Gradient with one layer writing backpropagation by hand\n",
    "\n",
    "Before you use the gradient you found using autograd, you will have to find the gradient \"manually\", to better understand how the backpropagation computation works. To do backpropagation \"manually\", you will need to write out expressions for many derivatives along the computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the gradient of the cost function wrt. the weight and bias. This is quite hard to do directly, so we instead use the chain rule to combine multiple derivatives which are easier to compute.\n",
    "\n",
    "$$\n",
    "\\frac{dC}{dW} = \\frac{dC}{da}\\frac{da}{dz}\\frac{dz}{dW}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dC}{db} = \\frac{dC}{da}\\frac{da}{dz}\\frac{dz}{db}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Which intermediary results can be reused between the two expressions?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer 3a):__\n",
    "The gradient of the cost function with respect to the weights:\n",
    "$$\n",
    "\\frac{dC}{dW} = \\frac{dC}{da}\\frac{da}{dz}\\frac{dz}{dW}\n",
    "$$\n",
    "\n",
    "We have:\n",
    "* $z^l = W^l*a^{l-1} + b^l$\n",
    "* $a^l = \\sigma(z^l)$\n",
    "\n",
    "So:\n",
    "* $\\frac{\\partial z^l}{\\partial W^l} = a^{l-1}$\n",
    "* $\\frac{\\partial z^l}{\\partial a^{l-1}} = W^l$\n",
    "\n",
    "In the case of Sigmoid being the activation function, we then have:\n",
    "* $\\sigma(z) = \\frac{1}{1 + e^{-z}}$\n",
    "* $\\frac{\\partial a^l}{\\partial z^l} = \\sigma ' = \\sigma(z^l) \\cdot (1 - \\sigma(z^l)) = a^l(1 - a^l)$\n",
    "\n",
    "In the case of MSE being the cost function, we have:\n",
    "* $C = \\frac{1}{2} (a^l - y)^2 = \\frac{1}{2} ((a^l)^2 - 2 a^ly + y^2)$\n",
    "* $\\frac{\\partial C}{\\partial a^l} = (a^l - y)$\n",
    "\n",
    "Then: $\\frac{dC}{dW} = (a^l - y) \\cdot a^l(1 - a^l) \\cdot a^{l-1}$\n",
    "\n",
    "And we can define: $\\delta^l = \\frac{\\partial C}{\\partial a^l} \\cdot \\sigma '$, which yields: $\\frac{dC}{dW} = \\delta^l \\cdot a^{l-1}$ \n",
    "\n",
    "\n",
    "Now, for the gradient of the bias:\n",
    "\n",
    "$$\n",
    "\\frac{dC}{db} = \\frac{dC}{da}\\frac{da}{dz}\\frac{dz}{db}\n",
    "$$\n",
    "\n",
    "Using what we already found, we have: $\\frac{dz}{db} = 1$, which leaves us with: $\\frac{dC}{db} = \\delta^l$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b)** What is the derivative of the cost wrt. the final activation? You can use the autograd calculation to make sure you get the correct result. Remember that we compute the mean in mse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.28648394 -0.27523393  0.13254047]\n",
      "[ 0.28648394 -0.27523393  0.13254047]\n"
     ]
    }
   ],
   "source": [
    "z = W @ x + b\n",
    "a = sigmoid(z)\n",
    "\n",
    "predict = a\n",
    "\n",
    "def mse_der(predict, target):\n",
    "    return 2*(predict - target)/predict.size\n",
    "\n",
    "print(mse_der(predict, target))\n",
    "\n",
    "cost_autograd = grad(mse, 0)\n",
    "print(cost_autograd(predict, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** What is the expression for the derivative of the sigmoid activation function? You can use the autograd calculation to make sure you get the correct result.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21560084 0.22277944 0.20907917]\n",
      "[0.21560084 0.22277944 0.20907917]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid_der(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "\n",
    "print(sigmoid_der(z))\n",
    "\n",
    "sigmoid_autograd = elementwise_grad(sigmoid, 0)\n",
    "print(sigmoid_autograd(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Using the two derivatives you just computed, compute this intermetidary gradient you will use later:\n",
    "\n",
    "$$\n",
    "\\frac{dC}{dz} = \\frac{dC}{da}\\frac{da}{dz}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dC_da = mse_der(predict, target)\n",
    "dC_dz = dC_da * sigmoid_der(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** What is the derivative of the intermediary z wrt. the weight and bias? What should the shapes be? The one for the weights is a little tricky, it can be easier to play around in the next exercise first. You can also try computing it with autograd to get a hint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer 3e):__\n",
    "$$\n",
    "\\frac{dC}{dz} = \\frac{dC}{da}\\frac{da}{dz}\n",
    "$$\n",
    "\n",
    "This is the cost function derivated with respect to z, which is the expression which will go through the activation function of the layer and afterwards be sent as output to the next layer.\n",
    "\n",
    "$$\n",
    "\\frac{dC}{dz} = \\frac{dC}{da}\\frac{da}{dz}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac{2}{n}(a^l - y) * \\sigma(z^l)*(1 - \\sigma(z^l))\n",
    "$$\n",
    "\n",
    "(I dont really understand the question, isnt this what was in 3a?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**f)** Now combine the expressions you have worked with so far to compute the gradients! Note that you always need to do a feed forward pass while saving the zs and as before you do backpropagation, as they are used in the derivative expressions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02138296  0.01262527]\n",
      " [-0.02122727 -0.01253334]\n",
      " [ 0.00959348  0.00566434]] [ 0.06176618 -0.06131646  0.02771145]\n"
     ]
    }
   ],
   "source": [
    "dC_da = (2/predict.size)*(predict - target)\n",
    "dC_dz = dC_da * sigmoid_der(z)\n",
    "dC_dW = np.outer(dC_dz, x)\n",
    "dC_db = dC_dz\n",
    "\n",
    "print(dC_dW, dC_db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the same results as with autograd.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02138296  0.01262527]\n",
      " [-0.02122727 -0.01253334]\n",
      " [ 0.00959348  0.00566434]] [ 0.06176618 -0.06131646  0.02771145]\n"
     ]
    }
   ],
   "source": [
    "W_g, b_g = autograd_one_layer(W, b, x, target)\n",
    "print(W_g, b_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 - Gradient with two layers writing backpropagation by hand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have implemented backpropagation for one layer, you have found most of the expressions you will need for more layers. Let's move up to two layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(2)\n",
    "target = np.random.rand(4)\n",
    "\n",
    "W1 = np.random.rand(3, 2)\n",
    "b1 = np.random.rand(3)\n",
    "\n",
    "W2 = np.random.rand(4, 3)\n",
    "b2 = np.random.rand(4)\n",
    "\n",
    "layers = [(W1, b1), (W2, b2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = W1 @ x + b1\n",
    "a1 = sigmoid(z1)\n",
    "z2 = W2 @ a1 + b2\n",
    "a2 = sigmoid(z2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by computing the gradients of the last layer, as the gradients must be propagated backwards from the end.\n",
    "\n",
    "**a)** Compute the gradients of the last layer, just like you did the single layer in the previous exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "dC_da2 = (2/a2.size)*(a2 - target)\n",
    "dC_dz2 = dC_da2 * sigmoid_der(z2)\n",
    "dC_dW2 = np.outer(dC_dz2, a1)\n",
    "dC_db2 = dC_dz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the derivative of the cost wrt. the activation of the first layer, we need a new expression, the one furthest to the right in the following.\n",
    "\n",
    "$$\n",
    "\\frac{dC}{da_1} = \\frac{dC}{dz_2}\\frac{dz_2}{da_1}\n",
    "$$\n",
    "\n",
    "**b)** What is the derivative of the second layer intermetiate wrt. the first layer activation? (First recall how you compute $z_2$)\n",
    "\n",
    "$$\n",
    "\\frac{dz_2}{da_1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer 4b):__\n",
    "$z_2 = W_2*a_1 + b_2$, so:\n",
    "\n",
    "$$\\frac{dz_2}{da_1} = W_2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c)** Use this expression, together with expressions which are equivelent to ones for the last layer to compute all the derivatives of the first layer.\n",
    "\n",
    "$$\n",
    "\\frac{dC}{dW_1} = \\frac{dC}{da_1}\\frac{da_1}{dz_1}\\frac{dz_1}{dW_1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{dC}{db_1} = \\frac{dC}{da_1}\\frac{da_1}{dz_1}\\frac{dz_1}{db_1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dC_da1 = W2.T @ dC_dz2 \n",
    "dC_dz1 = dC_da1 * sigmoid_der(z1)\n",
    "dC_dW1 = np.outer(dC_dz1, x)\n",
    "dC_db1 = dC_dz1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00941925 0.00689284]\n",
      " [0.00657652 0.00481258]\n",
      " [0.00802484 0.00587243]] [0.01203051 0.0083997  0.01024954]\n",
      "[[0.03138038 0.03263823 0.03061599]\n",
      " [0.02292424 0.02384314 0.02236584]\n",
      " [0.02538801 0.02640567 0.02476959]\n",
      " [0.00474303 0.00493315 0.00462749]] [0.03985282 0.02911359 0.03224256 0.00602361]\n"
     ]
    }
   ],
   "source": [
    "print(dC_dW1, dC_db1)\n",
    "print(dC_dW2, dC_db2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d)** Make sure you got the same gradient as the following code which uses autograd to do backpropagation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_two_layers(layers, x):\n",
    "    W1, b1 = layers[0]\n",
    "    z1 = W1 @ x + b1\n",
    "    a1 = sigmoid(z1)\n",
    "\n",
    "    W2, b2 = layers[1]\n",
    "    z2 = W2 @ a1 + b2\n",
    "    a2 = sigmoid(z2)\n",
    "\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([[0.00941925, 0.00689284],\n",
       "         [0.00657652, 0.00481258],\n",
       "         [0.00802484, 0.00587243]]),\n",
       "  array([0.01203051, 0.0083997 , 0.01024954])),\n",
       " (array([[0.03138038, 0.03263823, 0.03061599],\n",
       "         [0.02292424, 0.02384314, 0.02236584],\n",
       "         [0.02538801, 0.02640567, 0.02476959],\n",
       "         [0.00474303, 0.00493315, 0.00462749]]),\n",
       "  array([0.03985282, 0.02911359, 0.03224256, 0.00602361]))]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cost_two_layers(layers, x, target):\n",
    "    predict = feed_forward_two_layers(layers, x)\n",
    "    return mse(predict, target)\n",
    "\n",
    "grad_two_layers = grad(cost_two_layers, 0)\n",
    "g = grad_two_layers(layers, x, target)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00941925 0.00689284]\n",
      " [0.00657652 0.00481258]\n",
      " [0.00802484 0.00587243]]\n",
      "\n",
      "[0.01203051 0.0083997  0.01024954]\n"
     ]
    }
   ],
   "source": [
    "print(dC_dW1)\n",
    "print()\n",
    "print(dC_db1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.03138038 0.03263823 0.03061599]\n",
      " [0.02292424 0.02384314 0.02236584]\n",
      " [0.02538801 0.02640567 0.02476959]\n",
      " [0.00474303 0.00493315 0.00462749]]\n",
      "\n",
      "[0.03985282 0.02911359 0.03224256 0.00602361]\n"
     ]
    }
   ],
   "source": [
    "print(dC_dW2)\n",
    "print()\n",
    "print(dC_db2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**e)** How would you use the gradient from this layer to compute the gradient of an even earlier layer? Would the expressions be any different?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer 4e):__\n",
    "In back propagation, to find the gradients of an earlier layer, the chain rule applies. So the method and qlgorithm is similar, but the length of the expressions increase when using the chain rule. It evolves because the input to one layer is given by the output of an earlier layer, and such all layers connect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 - Gradient with any number of layers writing backpropagation by hand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done on getting this far! Now it's time to compute the gradient with any number of layers.\n",
    "\n",
    "First, some code from the general neural network code from last week. Note that we are still sending in one input vector at a time. We will change it to use batched inputs later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layers(network_input_size, layer_output_sizes):\n",
    "    layers = []\n",
    "\n",
    "    i_size = network_input_size\n",
    "    for layer_output_size in layer_output_sizes:\n",
    "        W = np.random.randn(layer_output_size, i_size)\n",
    "        b = np.random.randn(layer_output_size)\n",
    "        layers.append((W, b))\n",
    "\n",
    "        i_size = layer_output_size\n",
    "    return layers\n",
    "\n",
    "\n",
    "def feed_forward(input, layers, activation_funcs):\n",
    "    a = input\n",
    "    for (W, b), activation_func in zip(layers, activation_funcs):\n",
    "        z = W @ a + b\n",
    "        a = activation_func(z)\n",
    "    return a\n",
    "\n",
    "\n",
    "def cost(layers, input, activation_funcs, target):\n",
    "    predict = feed_forward(input, layers, activation_funcs)\n",
    "    return mse(predict, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have already have noticed a very important detail in backpropagation: You need the values from the forward pass to compute all the gradients! The feed forward method above is great for efficiency and for using autograd, as it only cares about computing the final output, but now we need to also save the results along the way.\n",
    "\n",
    "Here is a function which does that for you.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward_saver(input, layers, activation_funcs):\n",
    "    layer_inputs = []\n",
    "    zs = []\n",
    "    a = input\n",
    "    for (W, b), activation_func in zip(layers, activation_funcs):\n",
    "        layer_inputs.append(a)\n",
    "        z = W @ a + b\n",
    "        a = activation_func(z)\n",
    "\n",
    "        zs.append(z)\n",
    "\n",
    "    return layer_inputs, zs, a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Now, complete the backpropagation function so that it returns the gradient of the cost function wrt. all the weigths and biases. Use the autograd calculation below to make sure you get the correct answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(\n",
    "    input, layers, activation_funcs, target, activation_ders, cost_der=mse_der\n",
    "):\n",
    "    layer_inputs, zs, predict = feed_forward_saver(input, layers, activation_funcs)\n",
    "\n",
    "    layer_grads = [() for layer in layers]\n",
    "\n",
    "    # We loop over the layers, from the last to the first\n",
    "    for i in reversed(range(len(layers))):\n",
    "        layer_input, z, activation_der = layer_inputs[i], zs[i], activation_ders[i]\n",
    "\n",
    "        if i == len(layers) - 1:\n",
    "            # For last layer we use cost derivative as dC_da(L) can be computed directly\n",
    "            dC_da = cost_der(predict, target)\n",
    "        else:\n",
    "            # For other layers we build on previous z derivative, as dC_da(i) = dC_dz(i+1) * dz(i+1)_da(i)\n",
    "            (W, b) = layers[i + 1]\n",
    "            dC_da = dC_dz @ W\n",
    "\n",
    "        dC_dz = dC_da * activation_der(z)\n",
    "        dC_dW = np.outer(dC_dz, layer_input)\n",
    "        dC_db = dC_dz\n",
    "\n",
    "        layer_grads[i] = (dC_dW, dC_db)\n",
    "\n",
    "    return layer_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_input_size = 2\n",
    "layer_output_sizes = [3, 4]\n",
    "activation_funcs = [sigmoid, ReLU]\n",
    "activation_ders = [sigmoid_der, ReLU_der]\n",
    "\n",
    "layers = create_layers(network_input_size, layer_output_sizes)\n",
    "\n",
    "x = np.random.rand(network_input_size)\n",
    "target = np.random.rand(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dC/dW for layer 1:\n",
      "[[ 0.0001293   0.00200097]\n",
      " [-0.00271749 -0.04205568]\n",
      " [ 0.00339058  0.05247238]]\n",
      "dC/db for layer 1:\n",
      "[ 0.00268642 -0.05646207  0.07044707]\n",
      "dC/dW for layer 2:\n",
      "[[-0.         -0.         -0.        ]\n",
      " [-0.         -0.         -0.        ]\n",
      " [ 0.02357543  0.04972076  0.07664738]\n",
      " [ 0.08242759  0.17384038  0.26798484]]\n",
      "dC/db for layer 2:\n",
      "[-0.         -0.          0.14253015  0.49833302]\n"
     ]
    }
   ],
   "source": [
    "layer_grads = backpropagation(x, layers, activation_funcs, target, activation_ders)\n",
    "print('dC/dW for layer 1:')\n",
    "print(layer_grads[0][0])\n",
    "print('dC/db for layer 1:')\n",
    "print(layer_grads[0][1])\n",
    "print('dC/dW for layer 2:')\n",
    "print(layer_grads[1][0])\n",
    "print('dC/db for layer 2:')\n",
    "print(layer_grads[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dC/dW for layer 1:\n",
      "[[ 0.0001293   0.00200097]\n",
      " [-0.00271749 -0.04205568]\n",
      " [ 0.00339058  0.05247238]]\n",
      "dC/db for layer 1:\n",
      "[ 0.00268642 -0.05646207  0.07044707]\n",
      "dC/dW for layer 2:\n",
      "[[0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.02357543 0.04972076 0.07664738]\n",
      " [0.08242759 0.17384038 0.26798484]]\n",
      "dC/db for layer 2:\n",
      "[0.         0.         0.14253015 0.49833302]\n"
     ]
    }
   ],
   "source": [
    "cost_grad = grad(cost, 0)\n",
    "g = cost_grad(layers, x, [sigmoid, ReLU], target)\n",
    "\n",
    "print('dC/dW for layer 1:')\n",
    "print(g[0][0])\n",
    "print('dC/db for layer 1:')\n",
    "print(g[0][1])\n",
    "print('dC/dW for layer 2:')\n",
    "print(g[1][0])\n",
    "print('dC/db for layer 2:')\n",
    "print(g[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 - Batched inputs\n",
    "\n",
    "Make new versions of all the functions in exercise 5 which now take batched inputs instead. See last weeks exercise 5 for details on how to batch inputs to neural networks. You will also need to update the backpropogation function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layers_batch(network_input_size, layer_output_sizes):\n",
    "    layers = []\n",
    "    i_size = network_input_size\n",
    "\n",
    "    for layer_output_size in layer_output_sizes:\n",
    "        W = np.random.randn(i_size, layer_output_size)\n",
    "        b = np.random.randn(layer_output_size, 1)\n",
    "        layers.append((W, b))\n",
    "\n",
    "        i_size = layer_output_size\n",
    "    return layers\n",
    "\n",
    "\n",
    "def feed_forward_batch(inputs, layers, activation_funcs):\n",
    "    a = inputs\n",
    "    for (W, b), activation_func in zip(layers, activation_funcs):\n",
    "        z = W.T @ a + b\n",
    "        a = activation_func(z)\n",
    "    return a\n",
    "\n",
    "def feed_forward_saver_batch(inputs, layers, activation_funcs):\n",
    "    layer_inputs = []\n",
    "    zs = []\n",
    "    a = inputs\n",
    "    for (W, b), activation_func in zip(layers, activation_funcs):\n",
    "        layer_inputs.append(a)\n",
    "        z = W.T @ a + b\n",
    "        zs.append(z)\n",
    "        a = activation_func(z)\n",
    "    return layer_inputs, zs, a\n",
    "\n",
    "\n",
    "def cost_batch(layers, inputs, activation_funcs, target):\n",
    "    predictions = feed_forward_batch(inputs, layers, activation_funcs)\n",
    "    mse_per_sample = np.mean((predictions - target) ** 2, axis=0)\n",
    "    return mse_per_sample\n",
    "\n",
    "\n",
    "def backpropagation_batch(\n",
    "    inputs, layers, activation_funcs, target, activation_ders, cost_der=mse_der\n",
    "):\n",
    "    layer_inputs, zs, predictions = feed_forward_saver_batch(inputs, layers, activation_funcs)\n",
    "    batch_size = inputs.shape[1]\n",
    "\n",
    "    layer_grads = [() for l in layers]\n",
    "\n",
    "    # Loop over layers backward\n",
    "    for i in reversed(range(len(layers))):\n",
    "        layer_input, z, activation_der = layer_inputs[i], zs[i], activation_ders[i]\n",
    "\n",
    "        if i == len(layers) - 1:\n",
    "            # Last layer: derivative of cost w.r.t activation\n",
    "            dC_da = cost_der(predictions, target)  # shape: (output_size, batch_size)\n",
    "        else:\n",
    "            W_next, b_next = layers[i + 1]\n",
    "            dC_da = W_next @ dC_dz  \n",
    "\n",
    "        dC_dz = dC_da * activation_der(z)\n",
    "        dC_dW = (layer_input @ dC_dz.T) / batch_size\n",
    "        dC_db = np.mean(dC_dz, axis=1, keepdims=True)\n",
    "\n",
    "        layer_grads[i] = (dC_dW, dC_db)\n",
    "\n",
    "    return layer_grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "network_input_size = 2\n",
    "layer_output_sizes = [3, 4]\n",
    "activation_funcs = [sigmoid, ReLU]\n",
    "activation_ders = [sigmoid_der, ReLU_der]\n",
    "\n",
    "layers = create_layers_batch(network_input_size, layer_output_sizes)\n",
    "\n",
    "x = np.random.rand(network_input_size, batch_size)\n",
    "target = np.random.rand(4, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dC/dW for layer 1:\n",
      "[[0.01171041 0.01632465 0.00163746]\n",
      " [0.00908787 0.01474151 0.00148492]]\n",
      "dC/db for layer 1:\n",
      "[[0.01818251]\n",
      " [0.02461787]\n",
      " [0.00271486]]\n",
      "dC/dW for layer 2:\n",
      "[[0.         0.         0.         0.06821137]\n",
      " [0.         0.         0.         0.04162008]\n",
      " [0.         0.         0.         0.01149188]]\n",
      "dC/db for layer 2:\n",
      "[[0.        ]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.08737146]]\n"
     ]
    }
   ],
   "source": [
    "layer_grads = backpropagation_batch(x, layers, activation_funcs, target, activation_ders)\n",
    "print('dC/dW for layer 1:')\n",
    "print(layer_grads[0][0])\n",
    "print('dC/db for layer 1:')\n",
    "print(layer_grads[0][1])\n",
    "print('dC/dW for layer 2:')\n",
    "print(layer_grads[1][0])\n",
    "print('dC/db for layer 2:')\n",
    "print(layer_grads[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7 - Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a)** Complete exercise 6 and 7 from last week, but use your own backpropogation implementation to compute the gradient.\n",
    "- IMPORTANT: Do not implement the derivative terms for softmax and cross-entropy separately, it will be very hard!\n",
    "- Instead, use the fact that the derivatives multiplied together simplify to **prediction - target** (see [source1](https://medium.com/data-science/derivative-of-the-softmax-function-and-the-categorical-cross-entropy-loss-ffceefc081d1), [source2](https://shivammehta25.github.io/posts/deriving-categorical-cross-entropy-and-softmax/))\n",
    "\n",
    "**b)** Use stochastic gradient descent with momentum when you train your network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "scatter = ax.scatter(iris.data[:, 0], iris.data[:, 1], c=iris.target)\n",
    "ax.set(xlabel=iris.feature_names[0], ylabel=iris.feature_names[1])\n",
    "_ = ax.legend(\n",
    "    scatter.legend_elements()[0], iris.target_names, loc=\"lower right\", title=\"Classes\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = iris.data.T  # (4, 150)\n",
    "targets = np.zeros((3, len(iris.data)))  # (3, 150)\n",
    "for i, t in enumerate(iris.target):\n",
    "    targets[t, i] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "def softmax(z):\n",
    "    e_z = np.exp(z - np.max(z, axis=0, keepdims=True))\n",
    "    return e_z / np.sum(e_z, axis=0, keepdims=True)\n",
    "\n",
    "def cross_entropy(predict, target):\n",
    "    return -np.mean(np.sum(target * np.log(predict + 1e-8), axis=0))\n",
    "\n",
    "def cross_entropy_der(predictions, targets):\n",
    "    return predictions - targets\n",
    "\n",
    "def accuracy(predictions, targets):\n",
    "    pred_labels = np.argmax(predictions, axis=0)\n",
    "    true_labels = np.argmax(targets, axis=0)\n",
    "    return np.mean(pred_labels == true_labels)\n",
    "\n",
    "def train_network_momentum(\n",
    "    inputs, layers, activation_funcs, activation_ders,\n",
    "    targets, learning_rate=0.1, momentum=0.9, epochs=100, batch_size=10\n",
    "):\n",
    "    n_samples = inputs.shape[1]\n",
    "    velocities = [(np.zeros_like(W), np.zeros_like(b)) for (W, b) in layers]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        indices = np.random.permutation(n_samples)\n",
    "        inputs_shuffled = inputs[:, indices]\n",
    "        targets_shuffled = targets[:, indices]\n",
    "\n",
    "        for start in range(0, n_samples, batch_size):\n",
    "            end = start + batch_size\n",
    "            x_batch = inputs_shuffled[:, start:end]\n",
    "            y_batch = targets_shuffled[:, start:end]\n",
    "\n",
    "            grads = backpropagation_batch(\n",
    "                x_batch, layers, activation_funcs, y_batch,\n",
    "                activation_ders, cost_der=cross_entropy_der\n",
    "            )\n",
    "\n",
    "            for i, ((W, b), (dW, db)) in enumerate(zip(layers, grads)):\n",
    "                vW, vb = velocities[i]\n",
    "                vW = momentum * vW - learning_rate * dW\n",
    "                vb = momentum * vb - learning_rate * db\n",
    "                W += vW\n",
    "                b += vb\n",
    "                velocities[i] = (vW, vb)\n",
    "\n",
    "    return layers\n",
    "\n",
    "\n",
    "network_input_size = 4\n",
    "layer_output_sizes = [8, 3]\n",
    "activation_funcs = [sigmoid, softmax]\n",
    "activation_ders = [sigmoid_der, lambda z: 1]\n",
    "\n",
    "layers = create_layers_batch(network_input_size, layer_output_sizes)\n",
    "\n",
    "trained_layers = train_network_momentum(\n",
    "    inputs, layers, activation_funcs, activation_ders, targets,\n",
    "    learning_rate=0.01, momentum=0.9, epochs=100, batch_size=10\n",
    ")\n",
    "\n",
    "preds = feed_forward_batch(inputs, trained_layers, activation_funcs)\n",
    "print(\"Final accuracy:\", accuracy(preds, targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8 (Optional) - Object orientation\n",
    "\n",
    "Passing in the layers, activations functions, activation derivatives and cost derivatives into the functions each time leads to code which is easy to understand in isoloation, but messier when used in a larger context with data splitting, data scaling, gradient methods and so forth. Creating an object which stores these values can lead to code which is much easier to use.\n",
    "\n",
    "**a)** Write a neural network class. You are free to implement it how you see fit, though we strongly recommend to not save any input or output values as class attributes, nor let the neural network class handle gradient methods internally. Gradient methods should be handled outside, by performing general operations on the layer_grads list using functions or classes separate to the neural network.\n",
    "\n",
    "We provide here a skeleton structure which should get you started.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(\n",
    "        self,\n",
    "        network_input_size,\n",
    "        layer_output_sizes,\n",
    "        activation_funcs,\n",
    "        activation_ders,\n",
    "        cost_fun,\n",
    "        cost_der,\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        # Simple feed forward pass\n",
    "        pass\n",
    "\n",
    "    def cost(self, inputs, targets):\n",
    "        pass\n",
    "\n",
    "    def _feed_forward_saver(self, inputs):\n",
    "        pass\n",
    "\n",
    "    def compute_gradient(self, inputs, targets):\n",
    "        pass\n",
    "\n",
    "    def update_weights(self, layer_grads):\n",
    "        pass\n",
    "\n",
    "    # These last two methods are not needed in the project, but they can be nice to have! The first one has a layers parameter so that you can use autograd on it\n",
    "    def autograd_compliant_predict(self, layers, inputs):\n",
    "        pass\n",
    "\n",
    "    def autograd_gradient(self, inputs, targets):\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercises",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
